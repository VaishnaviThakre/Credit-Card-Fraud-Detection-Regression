{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edf36ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08918b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77fdf13e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350fb6f5",
   "metadata": {},
   "source": [
    "Summarizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8da7a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b9f7a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.918649e-15</td>\n",
       "      <td>5.682686e-16</td>\n",
       "      <td>-8.761736e-15</td>\n",
       "      <td>2.811118e-15</td>\n",
       "      <td>-1.552103e-15</td>\n",
       "      <td>2.040130e-15</td>\n",
       "      <td>-1.698953e-15</td>\n",
       "      <td>-1.893285e-16</td>\n",
       "      <td>-3.147640e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.473120e-16</td>\n",
       "      <td>8.042109e-16</td>\n",
       "      <td>5.282512e-16</td>\n",
       "      <td>4.456271e-15</td>\n",
       "      <td>1.426896e-15</td>\n",
       "      <td>1.701640e-15</td>\n",
       "      <td>-3.662252e-16</td>\n",
       "      <td>-1.217809e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.918649e-15  5.682686e-16 -8.761736e-15  2.811118e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552103e-15  2.040130e-15 -1.698953e-15 -1.893285e-16 -3.147640e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.473120e-16  8.042109e-16  5.282512e-16  4.456271e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.426896e-15  1.701640e-15 -3.662252e-16 -1.217809e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f27a69b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df2be8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      284807\n",
       "V1        284807\n",
       "V2        284807\n",
       "V3        284807\n",
       "V4        284807\n",
       "V5        284807\n",
       "V6        284807\n",
       "V7        284807\n",
       "V8        284807\n",
       "V9        284807\n",
       "V10       284807\n",
       "V11       284807\n",
       "V12       284807\n",
       "V13       284807\n",
       "V14       284807\n",
       "V15       284807\n",
       "V16       284807\n",
       "V17       284807\n",
       "V18       284807\n",
       "V19       284807\n",
       "V20       284807\n",
       "V21       284807\n",
       "V22       284807\n",
       "V23       284807\n",
       "V24       284807\n",
       "V25       284807\n",
       "V26       284807\n",
       "V27       284807\n",
       "V28       284807\n",
       "Amount    284807\n",
       "Class     284807\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.notnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22661389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2937b79",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52502b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "284802    0\n",
       "284803    0\n",
       "284804    0\n",
       "284805    0\n",
       "284806    0\n",
       "Name: Class, Length: 284807, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class1 = df['Class']\n",
    "class1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df079f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "distinct_values = df['Class'].unique()\n",
    "print(distinct_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc8455e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b2ae440",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud = df.loc[df['Class']==1] #fraudlent data\n",
    "non_fraud = df.loc[df['Class']==0] #non-fraudlent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9a9fbae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>406.0</td>\n",
       "      <td>-2.312227</td>\n",
       "      <td>1.951992</td>\n",
       "      <td>-1.609851</td>\n",
       "      <td>3.997906</td>\n",
       "      <td>-0.522188</td>\n",
       "      <td>-1.426545</td>\n",
       "      <td>-2.537387</td>\n",
       "      <td>1.391657</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517232</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>-0.465211</td>\n",
       "      <td>0.320198</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>-0.143276</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>472.0</td>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661696</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>529.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>4462.0</td>\n",
       "      <td>-2.303350</td>\n",
       "      <td>1.759247</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>2.330243</td>\n",
       "      <td>-0.821628</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>0.562320</td>\n",
       "      <td>-0.399147</td>\n",
       "      <td>-0.238253</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294166</td>\n",
       "      <td>-0.932391</td>\n",
       "      <td>0.172726</td>\n",
       "      <td>-0.087330</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>-0.542628</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>239.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6108</th>\n",
       "      <td>6986.0</td>\n",
       "      <td>-4.397974</td>\n",
       "      <td>1.358367</td>\n",
       "      <td>-2.592844</td>\n",
       "      <td>2.679787</td>\n",
       "      <td>-1.128131</td>\n",
       "      <td>-1.706536</td>\n",
       "      <td>-3.496197</td>\n",
       "      <td>-0.248778</td>\n",
       "      <td>-0.247768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573574</td>\n",
       "      <td>0.176968</td>\n",
       "      <td>-0.436207</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>-0.657488</td>\n",
       "      <td>-0.827136</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>59.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>7519.0</td>\n",
       "      <td>1.234235</td>\n",
       "      <td>3.019740</td>\n",
       "      <td>-4.304597</td>\n",
       "      <td>4.732795</td>\n",
       "      <td>3.624201</td>\n",
       "      <td>-1.357746</td>\n",
       "      <td>1.713445</td>\n",
       "      <td>-0.496358</td>\n",
       "      <td>-1.282858</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379068</td>\n",
       "      <td>-0.704181</td>\n",
       "      <td>-0.656805</td>\n",
       "      <td>-1.632653</td>\n",
       "      <td>1.488901</td>\n",
       "      <td>0.566797</td>\n",
       "      <td>-0.010016</td>\n",
       "      <td>0.146793</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279863</th>\n",
       "      <td>169142.0</td>\n",
       "      <td>-1.927883</td>\n",
       "      <td>1.125653</td>\n",
       "      <td>-4.518331</td>\n",
       "      <td>1.749293</td>\n",
       "      <td>-1.566487</td>\n",
       "      <td>-2.010494</td>\n",
       "      <td>-0.882850</td>\n",
       "      <td>0.697211</td>\n",
       "      <td>-2.064945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.778584</td>\n",
       "      <td>-0.319189</td>\n",
       "      <td>0.639419</td>\n",
       "      <td>-0.294885</td>\n",
       "      <td>0.537503</td>\n",
       "      <td>0.788395</td>\n",
       "      <td>0.292680</td>\n",
       "      <td>0.147968</td>\n",
       "      <td>390.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280143</th>\n",
       "      <td>169347.0</td>\n",
       "      <td>1.378559</td>\n",
       "      <td>1.289381</td>\n",
       "      <td>-5.004247</td>\n",
       "      <td>1.411850</td>\n",
       "      <td>0.442581</td>\n",
       "      <td>-1.326536</td>\n",
       "      <td>-1.413170</td>\n",
       "      <td>0.248525</td>\n",
       "      <td>-1.127396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370612</td>\n",
       "      <td>0.028234</td>\n",
       "      <td>-0.145640</td>\n",
       "      <td>-0.081049</td>\n",
       "      <td>0.521875</td>\n",
       "      <td>0.739467</td>\n",
       "      <td>0.389152</td>\n",
       "      <td>0.186637</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280149</th>\n",
       "      <td>169351.0</td>\n",
       "      <td>-0.676143</td>\n",
       "      <td>1.126366</td>\n",
       "      <td>-2.213700</td>\n",
       "      <td>0.468308</td>\n",
       "      <td>-1.120541</td>\n",
       "      <td>-0.003346</td>\n",
       "      <td>-2.234739</td>\n",
       "      <td>1.210158</td>\n",
       "      <td>-0.652250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751826</td>\n",
       "      <td>0.834108</td>\n",
       "      <td>0.190944</td>\n",
       "      <td>0.032070</td>\n",
       "      <td>-0.739695</td>\n",
       "      <td>0.471111</td>\n",
       "      <td>0.385107</td>\n",
       "      <td>0.194361</td>\n",
       "      <td>77.89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281144</th>\n",
       "      <td>169966.0</td>\n",
       "      <td>-3.113832</td>\n",
       "      <td>0.585864</td>\n",
       "      <td>-5.399730</td>\n",
       "      <td>1.817092</td>\n",
       "      <td>-0.840618</td>\n",
       "      <td>-2.943548</td>\n",
       "      <td>-2.208002</td>\n",
       "      <td>1.058733</td>\n",
       "      <td>-1.632333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583276</td>\n",
       "      <td>-0.269209</td>\n",
       "      <td>-0.456108</td>\n",
       "      <td>-0.183659</td>\n",
       "      <td>-0.328168</td>\n",
       "      <td>0.606116</td>\n",
       "      <td>0.884876</td>\n",
       "      <td>-0.253700</td>\n",
       "      <td>245.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281674</th>\n",
       "      <td>170348.0</td>\n",
       "      <td>1.991976</td>\n",
       "      <td>0.158476</td>\n",
       "      <td>-2.583441</td>\n",
       "      <td>0.408670</td>\n",
       "      <td>1.151147</td>\n",
       "      <td>-0.096695</td>\n",
       "      <td>0.223050</td>\n",
       "      <td>-0.068384</td>\n",
       "      <td>0.577829</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.164350</td>\n",
       "      <td>-0.295135</td>\n",
       "      <td>-0.072173</td>\n",
       "      <td>-0.450261</td>\n",
       "      <td>0.313267</td>\n",
       "      <td>-0.289617</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>-0.015309</td>\n",
       "      <td>42.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>492 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "541        406.0 -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545   \n",
       "623        472.0 -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823   \n",
       "4920      4462.0 -2.303350  1.759247 -0.359745  2.330243 -0.821628 -0.075788   \n",
       "6108      6986.0 -4.397974  1.358367 -2.592844  2.679787 -1.128131 -1.706536   \n",
       "6329      7519.0  1.234235  3.019740 -4.304597  4.732795  3.624201 -1.357746   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "279863  169142.0 -1.927883  1.125653 -4.518331  1.749293 -1.566487 -2.010494   \n",
       "280143  169347.0  1.378559  1.289381 -5.004247  1.411850  0.442581 -1.326536   \n",
       "280149  169351.0 -0.676143  1.126366 -2.213700  0.468308 -1.120541 -0.003346   \n",
       "281144  169966.0 -3.113832  0.585864 -5.399730  1.817092 -0.840618 -2.943548   \n",
       "281674  170348.0  1.991976  0.158476 -2.583441  0.408670  1.151147 -0.096695   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "541    -2.537387  1.391657 -2.770089  ...  0.517232 -0.035049 -0.465211   \n",
       "623     0.325574 -0.067794 -0.270953  ...  0.661696  0.435477  1.375966   \n",
       "4920    0.562320 -0.399147 -0.238253  ... -0.294166 -0.932391  0.172726   \n",
       "6108   -3.496197 -0.248778 -0.247768  ...  0.573574  0.176968 -0.436207   \n",
       "6329    1.713445 -0.496358 -1.282858  ... -0.379068 -0.704181 -0.656805   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "279863 -0.882850  0.697211 -2.064945  ...  0.778584 -0.319189  0.639419   \n",
       "280143 -1.413170  0.248525 -1.127396  ...  0.370612  0.028234 -0.145640   \n",
       "280149 -2.234739  1.210158 -0.652250  ...  0.751826  0.834108  0.190944   \n",
       "281144 -2.208002  1.058733 -1.632333  ...  0.583276 -0.269209 -0.456108   \n",
       "281674  0.223050 -0.068384  0.577829  ... -0.164350 -0.295135 -0.072173   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "541     0.320198  0.044519  0.177840  0.261145 -0.143276    0.00      1  \n",
       "623    -0.293803  0.279798 -0.145362 -0.252773  0.035764  529.00      1  \n",
       "4920   -0.087330 -0.156114 -0.542628  0.039566 -0.153029  239.93      1  \n",
       "6108   -0.053502  0.252405 -0.657488 -0.827136  0.849573   59.00      1  \n",
       "6329   -1.632653  1.488901  0.566797 -0.010016  0.146793    1.00      1  \n",
       "...          ...       ...       ...       ...       ...     ...    ...  \n",
       "279863 -0.294885  0.537503  0.788395  0.292680  0.147968  390.00      1  \n",
       "280143 -0.081049  0.521875  0.739467  0.389152  0.186637    0.76      1  \n",
       "280149  0.032070 -0.739695  0.471111  0.385107  0.194361   77.89      1  \n",
       "281144 -0.183659 -0.328168  0.606116  0.884876 -0.253700  245.00      1  \n",
       "281674 -0.450261  0.313267 -0.289617  0.002988 -0.015309   42.53      1  \n",
       "\n",
       "[492 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc00db00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284315 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284315 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d18d53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492, 31)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae10a07f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284315, 31)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_fraud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12fb5fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>492.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>80746.806911</td>\n",
       "      <td>-4.771948</td>\n",
       "      <td>3.623778</td>\n",
       "      <td>-7.033281</td>\n",
       "      <td>4.542029</td>\n",
       "      <td>-3.151225</td>\n",
       "      <td>-1.397737</td>\n",
       "      <td>-5.568731</td>\n",
       "      <td>0.570636</td>\n",
       "      <td>-2.581123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.713588</td>\n",
       "      <td>0.014049</td>\n",
       "      <td>-0.040308</td>\n",
       "      <td>-0.105130</td>\n",
       "      <td>0.041449</td>\n",
       "      <td>0.051648</td>\n",
       "      <td>0.170575</td>\n",
       "      <td>0.075667</td>\n",
       "      <td>122.211321</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47835.365138</td>\n",
       "      <td>6.783687</td>\n",
       "      <td>4.291216</td>\n",
       "      <td>7.110937</td>\n",
       "      <td>2.873318</td>\n",
       "      <td>5.372468</td>\n",
       "      <td>1.858124</td>\n",
       "      <td>7.206773</td>\n",
       "      <td>6.797831</td>\n",
       "      <td>2.500896</td>\n",
       "      <td>...</td>\n",
       "      <td>3.869304</td>\n",
       "      <td>1.494602</td>\n",
       "      <td>1.579642</td>\n",
       "      <td>0.515577</td>\n",
       "      <td>0.797205</td>\n",
       "      <td>0.471679</td>\n",
       "      <td>1.376766</td>\n",
       "      <td>0.547291</td>\n",
       "      <td>256.683288</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>406.000000</td>\n",
       "      <td>-30.552380</td>\n",
       "      <td>-8.402154</td>\n",
       "      <td>-31.103685</td>\n",
       "      <td>-1.313275</td>\n",
       "      <td>-22.105532</td>\n",
       "      <td>-6.406267</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>-41.044261</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>...</td>\n",
       "      <td>-22.797604</td>\n",
       "      <td>-8.887017</td>\n",
       "      <td>-19.254328</td>\n",
       "      <td>-2.028024</td>\n",
       "      <td>-4.781606</td>\n",
       "      <td>-1.152671</td>\n",
       "      <td>-7.263482</td>\n",
       "      <td>-1.869290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>41241.500000</td>\n",
       "      <td>-6.036063</td>\n",
       "      <td>1.188226</td>\n",
       "      <td>-8.643489</td>\n",
       "      <td>2.373050</td>\n",
       "      <td>-4.792835</td>\n",
       "      <td>-2.501511</td>\n",
       "      <td>-7.965295</td>\n",
       "      <td>-0.195336</td>\n",
       "      <td>-3.872383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041787</td>\n",
       "      <td>-0.533764</td>\n",
       "      <td>-0.342175</td>\n",
       "      <td>-0.436809</td>\n",
       "      <td>-0.314348</td>\n",
       "      <td>-0.259416</td>\n",
       "      <td>-0.020025</td>\n",
       "      <td>-0.108868</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>75568.500000</td>\n",
       "      <td>-2.342497</td>\n",
       "      <td>2.717869</td>\n",
       "      <td>-5.075257</td>\n",
       "      <td>4.177147</td>\n",
       "      <td>-1.522962</td>\n",
       "      <td>-1.424616</td>\n",
       "      <td>-3.034402</td>\n",
       "      <td>0.621508</td>\n",
       "      <td>-2.208768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592146</td>\n",
       "      <td>0.048434</td>\n",
       "      <td>-0.073135</td>\n",
       "      <td>-0.060795</td>\n",
       "      <td>0.088371</td>\n",
       "      <td>0.004321</td>\n",
       "      <td>0.394926</td>\n",
       "      <td>0.146344</td>\n",
       "      <td>9.250000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>128483.000000</td>\n",
       "      <td>-0.419200</td>\n",
       "      <td>4.971257</td>\n",
       "      <td>-2.276185</td>\n",
       "      <td>6.348729</td>\n",
       "      <td>0.214562</td>\n",
       "      <td>-0.413216</td>\n",
       "      <td>-0.945954</td>\n",
       "      <td>1.764879</td>\n",
       "      <td>-0.787850</td>\n",
       "      <td>...</td>\n",
       "      <td>1.244611</td>\n",
       "      <td>0.617474</td>\n",
       "      <td>0.308378</td>\n",
       "      <td>0.285328</td>\n",
       "      <td>0.456515</td>\n",
       "      <td>0.396733</td>\n",
       "      <td>0.826029</td>\n",
       "      <td>0.381152</td>\n",
       "      <td>105.890000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>170348.000000</td>\n",
       "      <td>2.132386</td>\n",
       "      <td>22.057729</td>\n",
       "      <td>2.250210</td>\n",
       "      <td>12.114672</td>\n",
       "      <td>11.095089</td>\n",
       "      <td>6.474115</td>\n",
       "      <td>5.802537</td>\n",
       "      <td>20.007208</td>\n",
       "      <td>3.353525</td>\n",
       "      <td>...</td>\n",
       "      <td>27.202839</td>\n",
       "      <td>8.361985</td>\n",
       "      <td>5.466230</td>\n",
       "      <td>1.091435</td>\n",
       "      <td>2.208209</td>\n",
       "      <td>2.745261</td>\n",
       "      <td>3.052358</td>\n",
       "      <td>1.779364</td>\n",
       "      <td>2125.870000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time          V1          V2          V3          V4  \\\n",
       "count     492.000000  492.000000  492.000000  492.000000  492.000000   \n",
       "mean    80746.806911   -4.771948    3.623778   -7.033281    4.542029   \n",
       "std     47835.365138    6.783687    4.291216    7.110937    2.873318   \n",
       "min       406.000000  -30.552380   -8.402154  -31.103685   -1.313275   \n",
       "25%     41241.500000   -6.036063    1.188226   -8.643489    2.373050   \n",
       "50%     75568.500000   -2.342497    2.717869   -5.075257    4.177147   \n",
       "75%    128483.000000   -0.419200    4.971257   -2.276185    6.348729   \n",
       "max    170348.000000    2.132386   22.057729    2.250210   12.114672   \n",
       "\n",
       "               V5          V6          V7          V8          V9  ...  \\\n",
       "count  492.000000  492.000000  492.000000  492.000000  492.000000  ...   \n",
       "mean    -3.151225   -1.397737   -5.568731    0.570636   -2.581123  ...   \n",
       "std      5.372468    1.858124    7.206773    6.797831    2.500896  ...   \n",
       "min    -22.105532   -6.406267  -43.557242  -41.044261  -13.434066  ...   \n",
       "25%     -4.792835   -2.501511   -7.965295   -0.195336   -3.872383  ...   \n",
       "50%     -1.522962   -1.424616   -3.034402    0.621508   -2.208768  ...   \n",
       "75%      0.214562   -0.413216   -0.945954    1.764879   -0.787850  ...   \n",
       "max     11.095089    6.474115    5.802537   20.007208    3.353525  ...   \n",
       "\n",
       "              V21         V22         V23         V24         V25         V26  \\\n",
       "count  492.000000  492.000000  492.000000  492.000000  492.000000  492.000000   \n",
       "mean     0.713588    0.014049   -0.040308   -0.105130    0.041449    0.051648   \n",
       "std      3.869304    1.494602    1.579642    0.515577    0.797205    0.471679   \n",
       "min    -22.797604   -8.887017  -19.254328   -2.028024   -4.781606   -1.152671   \n",
       "25%      0.041787   -0.533764   -0.342175   -0.436809   -0.314348   -0.259416   \n",
       "50%      0.592146    0.048434   -0.073135   -0.060795    0.088371    0.004321   \n",
       "75%      1.244611    0.617474    0.308378    0.285328    0.456515    0.396733   \n",
       "max     27.202839    8.361985    5.466230    1.091435    2.208209    2.745261   \n",
       "\n",
       "              V27         V28       Amount  Class  \n",
       "count  492.000000  492.000000   492.000000  492.0  \n",
       "mean     0.170575    0.075667   122.211321    1.0  \n",
       "std      1.376766    0.547291   256.683288    0.0  \n",
       "min     -7.263482   -1.869290     0.000000    1.0  \n",
       "25%     -0.020025   -0.108868     1.000000    1.0  \n",
       "50%      0.394926    0.146344     9.250000    1.0  \n",
       "75%      0.826029    0.381152   105.890000    1.0  \n",
       "max      3.052358    1.779364  2125.870000    1.0  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cd66aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.000000</td>\n",
       "      <td>284315.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94838.202258</td>\n",
       "      <td>0.008258</td>\n",
       "      <td>-0.006271</td>\n",
       "      <td>0.012171</td>\n",
       "      <td>-0.007860</td>\n",
       "      <td>0.005453</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.009637</td>\n",
       "      <td>-0.000987</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001235</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>-0.000089</td>\n",
       "      <td>-0.000295</td>\n",
       "      <td>-0.000131</td>\n",
       "      <td>88.291022</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47484.015786</td>\n",
       "      <td>1.929814</td>\n",
       "      <td>1.636146</td>\n",
       "      <td>1.459429</td>\n",
       "      <td>1.399333</td>\n",
       "      <td>1.356952</td>\n",
       "      <td>1.329913</td>\n",
       "      <td>1.178812</td>\n",
       "      <td>1.161283</td>\n",
       "      <td>1.089372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.716743</td>\n",
       "      <td>0.723668</td>\n",
       "      <td>0.621541</td>\n",
       "      <td>0.605776</td>\n",
       "      <td>0.520673</td>\n",
       "      <td>0.482241</td>\n",
       "      <td>0.399847</td>\n",
       "      <td>0.329570</td>\n",
       "      <td>250.105092</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-48.325589</td>\n",
       "      <td>-5.683171</td>\n",
       "      <td>-113.743307</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-31.764946</td>\n",
       "      <td>-73.216718</td>\n",
       "      <td>-6.290730</td>\n",
       "      <td>...</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-44.807735</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-10.295397</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-22.565679</td>\n",
       "      <td>-15.430084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54230.000000</td>\n",
       "      <td>-0.917544</td>\n",
       "      <td>-0.599473</td>\n",
       "      <td>-0.884541</td>\n",
       "      <td>-0.850077</td>\n",
       "      <td>-0.689398</td>\n",
       "      <td>-0.766847</td>\n",
       "      <td>-0.551442</td>\n",
       "      <td>-0.208633</td>\n",
       "      <td>-0.640412</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228509</td>\n",
       "      <td>-0.542403</td>\n",
       "      <td>-0.161702</td>\n",
       "      <td>-0.354425</td>\n",
       "      <td>-0.317145</td>\n",
       "      <td>-0.327074</td>\n",
       "      <td>-0.070852</td>\n",
       "      <td>-0.052950</td>\n",
       "      <td>5.650000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84711.000000</td>\n",
       "      <td>0.020023</td>\n",
       "      <td>0.064070</td>\n",
       "      <td>0.182158</td>\n",
       "      <td>-0.022405</td>\n",
       "      <td>-0.053457</td>\n",
       "      <td>-0.273123</td>\n",
       "      <td>0.041138</td>\n",
       "      <td>0.022041</td>\n",
       "      <td>-0.049964</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029821</td>\n",
       "      <td>0.006736</td>\n",
       "      <td>-0.011147</td>\n",
       "      <td>0.041082</td>\n",
       "      <td>0.016417</td>\n",
       "      <td>-0.052227</td>\n",
       "      <td>0.001230</td>\n",
       "      <td>0.011199</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139333.000000</td>\n",
       "      <td>1.316218</td>\n",
       "      <td>0.800446</td>\n",
       "      <td>1.028372</td>\n",
       "      <td>0.737624</td>\n",
       "      <td>0.612181</td>\n",
       "      <td>0.399619</td>\n",
       "      <td>0.571019</td>\n",
       "      <td>0.326200</td>\n",
       "      <td>0.598230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185626</td>\n",
       "      <td>0.528407</td>\n",
       "      <td>0.147522</td>\n",
       "      <td>0.439869</td>\n",
       "      <td>0.350594</td>\n",
       "      <td>0.240671</td>\n",
       "      <td>0.090573</td>\n",
       "      <td>0.077962</td>\n",
       "      <td>77.050000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930</td>\n",
       "      <td>18.902453</td>\n",
       "      <td>9.382558</td>\n",
       "      <td>16.875344</td>\n",
       "      <td>34.801666</td>\n",
       "      <td>73.301626</td>\n",
       "      <td>120.589494</td>\n",
       "      <td>18.709255</td>\n",
       "      <td>15.594995</td>\n",
       "      <td>...</td>\n",
       "      <td>22.614889</td>\n",
       "      <td>10.503090</td>\n",
       "      <td>22.528412</td>\n",
       "      <td>4.584549</td>\n",
       "      <td>7.519589</td>\n",
       "      <td>3.517346</td>\n",
       "      <td>31.612198</td>\n",
       "      <td>33.847808</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time             V1             V2             V3  \\\n",
       "count  284315.000000  284315.000000  284315.000000  284315.000000   \n",
       "mean    94838.202258       0.008258      -0.006271       0.012171   \n",
       "std     47484.015786       1.929814       1.636146       1.459429   \n",
       "min         0.000000     -56.407510     -72.715728     -48.325589   \n",
       "25%     54230.000000      -0.917544      -0.599473      -0.884541   \n",
       "50%     84711.000000       0.020023       0.064070       0.182158   \n",
       "75%    139333.000000       1.316218       0.800446       1.028372   \n",
       "max    172792.000000       2.454930      18.902453       9.382558   \n",
       "\n",
       "                  V4             V5             V6             V7  \\\n",
       "count  284315.000000  284315.000000  284315.000000  284315.000000   \n",
       "mean       -0.007860       0.005453       0.002419       0.009637   \n",
       "std         1.399333       1.356952       1.329913       1.178812   \n",
       "min        -5.683171    -113.743307     -26.160506     -31.764946   \n",
       "25%        -0.850077      -0.689398      -0.766847      -0.551442   \n",
       "50%        -0.022405      -0.053457      -0.273123       0.041138   \n",
       "75%         0.737624       0.612181       0.399619       0.571019   \n",
       "max        16.875344      34.801666      73.301626     120.589494   \n",
       "\n",
       "                  V8             V9  ...            V21            V22  \\\n",
       "count  284315.000000  284315.000000  ...  284315.000000  284315.000000   \n",
       "mean       -0.000987       0.004467  ...      -0.001235      -0.000024   \n",
       "std         1.161283       1.089372  ...       0.716743       0.723668   \n",
       "min       -73.216718      -6.290730  ...     -34.830382     -10.933144   \n",
       "25%        -0.208633      -0.640412  ...      -0.228509      -0.542403   \n",
       "50%         0.022041      -0.049964  ...      -0.029821       0.006736   \n",
       "75%         0.326200       0.598230  ...       0.185626       0.528407   \n",
       "max        18.709255      15.594995  ...      22.614889      10.503090   \n",
       "\n",
       "                 V23            V24            V25            V26  \\\n",
       "count  284315.000000  284315.000000  284315.000000  284315.000000   \n",
       "mean        0.000070       0.000182      -0.000072      -0.000089   \n",
       "std         0.621541       0.605776       0.520673       0.482241   \n",
       "min       -44.807735      -2.836627     -10.295397      -2.604551   \n",
       "25%        -0.161702      -0.354425      -0.317145      -0.327074   \n",
       "50%        -0.011147       0.041082       0.016417      -0.052227   \n",
       "75%         0.147522       0.439869       0.350594       0.240671   \n",
       "max        22.528412       4.584549       7.519589       3.517346   \n",
       "\n",
       "                 V27            V28         Amount     Class  \n",
       "count  284315.000000  284315.000000  284315.000000  284315.0  \n",
       "mean       -0.000295      -0.000131      88.291022       0.0  \n",
       "std         0.399847       0.329570     250.105092       0.0  \n",
       "min       -22.565679     -15.430084       0.000000       0.0  \n",
       "25%        -0.070852      -0.052950       5.650000       0.0  \n",
       "50%         0.001230       0.011199      22.000000       0.0  \n",
       "75%         0.090573       0.077962      77.050000       0.0  \n",
       "max        31.612198      33.847808   25691.160000       0.0  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_fraud.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "100fd1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94838.202258</td>\n",
       "      <td>0.008258</td>\n",
       "      <td>-0.006271</td>\n",
       "      <td>0.012171</td>\n",
       "      <td>-0.007860</td>\n",
       "      <td>0.005453</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.009637</td>\n",
       "      <td>-0.000987</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000644</td>\n",
       "      <td>-0.001235</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>-0.000089</td>\n",
       "      <td>-0.000295</td>\n",
       "      <td>-0.000131</td>\n",
       "      <td>88.291022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80746.806911</td>\n",
       "      <td>-4.771948</td>\n",
       "      <td>3.623778</td>\n",
       "      <td>-7.033281</td>\n",
       "      <td>4.542029</td>\n",
       "      <td>-3.151225</td>\n",
       "      <td>-1.397737</td>\n",
       "      <td>-5.568731</td>\n",
       "      <td>0.570636</td>\n",
       "      <td>-2.581123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372319</td>\n",
       "      <td>0.713588</td>\n",
       "      <td>0.014049</td>\n",
       "      <td>-0.040308</td>\n",
       "      <td>-0.105130</td>\n",
       "      <td>0.041449</td>\n",
       "      <td>0.051648</td>\n",
       "      <td>0.170575</td>\n",
       "      <td>0.075667</td>\n",
       "      <td>122.211321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Time        V1        V2        V3        V4        V5  \\\n",
       "Class                                                                   \n",
       "0      94838.202258  0.008258 -0.006271  0.012171 -0.007860  0.005453   \n",
       "1      80746.806911 -4.771948  3.623778 -7.033281  4.542029 -3.151225   \n",
       "\n",
       "             V6        V7        V8        V9  ...       V20       V21  \\\n",
       "Class                                          ...                       \n",
       "0      0.002419  0.009637 -0.000987  0.004467  ... -0.000644 -0.001235   \n",
       "1     -1.397737 -5.568731  0.570636 -2.581123  ...  0.372319  0.713588   \n",
       "\n",
       "            V22       V23       V24       V25       V26       V27       V28  \\\n",
       "Class                                                                         \n",
       "0     -0.000024  0.000070  0.000182 -0.000072 -0.000089 -0.000295 -0.000131   \n",
       "1      0.014049 -0.040308 -0.105130  0.041449  0.051648  0.170575  0.075667   \n",
       "\n",
       "           Amount  \n",
       "Class              \n",
       "0       88.291022  \n",
       "1      122.211321  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Class').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ceacbf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "748708fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='Class', data=df)\n",
    "plt.title('Distribution of Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "147dd1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax=fraud.plot.scatter(x='Amount', y='Class', color='Orange', label='Fraud')\n",
    "non_fraud.plot.scatter(x='Amount', y='Class', color='Blue', label='No Fraud', ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd22b053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00, -1.35980713e+00, -7.27811733e-02, ...,\n",
       "         1.33558377e-01, -2.10530535e-02,  1.49620000e+02],\n",
       "       [ 0.00000000e+00,  1.19185711e+00,  2.66150712e-01, ...,\n",
       "        -8.98309914e-03,  1.47241692e-02,  2.69000000e+00],\n",
       "       [ 1.00000000e+00, -1.35835406e+00, -1.34016307e+00, ...,\n",
       "        -5.53527940e-02, -5.97518406e-02,  3.78660000e+02],\n",
       "       ...,\n",
       "       [ 1.72788000e+05,  1.91956501e+00, -3.01253846e-01, ...,\n",
       "         4.45477214e-03, -2.65608286e-02,  6.78800000e+01],\n",
       "       [ 1.72788000e+05, -2.40440050e-01,  5.30482513e-01, ...,\n",
       "         1.08820735e-01,  1.04532821e-01,  1.00000000e+01],\n",
       "       [ 1.72792000e+05, -5.33412522e-01, -1.89733337e-01, ...,\n",
       "        -2.41530880e-03,  1.36489143e-02,  2.17000000e+02]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=df.iloc[:,0:30].values\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8de87d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df.iloc[:,-1].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9360c319",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,random_state=2,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c38dfdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b619017a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=LinearRegression()\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a67bc6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00066828,  0.00059881, -0.0013353 , ...,  0.00017328,\n",
       "        0.00639721,  0.0145654 ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred  #predicted values     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2eb8612c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_test   #actual values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c449e9fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.546546192263651"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "a=r2_score(y_test,y_pred)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ac73a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.001335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.006718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.001421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56957</th>\n",
       "      <td>0</td>\n",
       "      <td>0.003569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56958</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.000090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56959</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56960</th>\n",
       "      <td>0</td>\n",
       "      <td>0.006397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56961</th>\n",
       "      <td>0</td>\n",
       "      <td>0.014565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56962 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Actual  Predicted\n",
       "0           0   0.000668\n",
       "1           0   0.000599\n",
       "2           0  -0.001335\n",
       "3           0   0.006718\n",
       "4           0  -0.001421\n",
       "...       ...        ...\n",
       "56957       0   0.003569\n",
       "56958       0  -0.000090\n",
       "56959       0   0.000173\n",
       "56960       0   0.006397\n",
       "56961       0   0.014565\n",
       "\n",
       "[56962 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.DataFrame({'Actual':y_test,'Predicted':y_pred})\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0463ac75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "TRAIN MODEL CLASSIFICATION REPORT\n",
      "____________________________________________________________________________________________________\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Fraud       1.00      0.49      0.66    227437\n",
      "       Fraud       0.00      1.00      0.01       408\n",
      "\n",
      "    accuracy                           0.49    227845\n",
      "   macro avg       0.50      0.74      0.33    227845\n",
      "weighted avg       1.00      0.49      0.66    227845\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "TEST MODEL CLASSIFICATION REPORT\n",
      "____________________________________________________________________________________________________\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Fraud       1.00      1.00      1.00     56878\n",
      "       Fraud       0.83      0.45      0.58        84\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.91      0.73      0.79     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def linear_regression(x_train, y_train, x_test):\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "    lr=LinearRegression()\n",
    "    lr.fit(x_train, y_train)\n",
    "    y_train_pred=lr.predict(x_train)\n",
    "    y_train_cl_report=classification_report(y_train, y_train_pred > 0, target_names = ['No Fraud', 'Fraud'])\n",
    "    print(\"_\"*100)\n",
    "    print(\"TRAIN MODEL CLASSIFICATION REPORT\")\n",
    "    print(\"_\"*100)\n",
    "    print(y_train_cl_report)\n",
    "    y_test_pred=lr.predict(x_test)\n",
    "    y_test_pred = [0 if i < 0.5 else 1 for i in y_test_pred]\n",
    "    y_test_cl_report=classification_report(y_test, y_test_pred, target_names = ['No Fraud', 'Fraud'])\n",
    "    print(\"_\"*100)\n",
    "    print(\"TEST MODEL CLASSIFICATION REPORT\")\n",
    "    print(\"_\"*100)\n",
    "    print(y_test_cl_report)\n",
    "    print(\"_\"*100)\n",
    "    return y_test_pred, lr\n",
    "\n",
    "y_test_pred, lr= linear_regression(x_train, y_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b800eb39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Actual', ylabel='Predicted'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.regplot(x='Actual',y='Predicted',data=df1,color='magenta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "157b858e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lmplot(x='Amount', y='Class', data=df, ci=None)\n",
    "\n",
    "plt.title('Linear Regression of Amount vs Class')\n",
    "plt.xlabel('Amount')\n",
    "plt.ylabel('Class')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8c4c352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[56870     8]\n",
      " [   46    38]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, fbeta_score\n",
    "\n",
    "# Convert regression predictions to binary classes based on a threshold\n",
    "threshold = 0.5 \n",
    "y_pred_binary = (y_pred > threshold).astype(int)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_binary)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9632c65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9990519995786665\n",
      "Precision: 0.8260869565217391\n",
      "Recall: 0.4523809523809524\n",
      "F2-score: 0.49738219895287955\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "precision = precision_score(y_test, y_pred_binary)\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "recall = recall_score(y_test, y_pred_binary)\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "f2score = fbeta_score(y_test, y_pred_binary, beta=2)\n",
    "print(\"F2-score:\", f2score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e530d6",
   "metadata": {},
   "source": [
    "from above that the linear regression model created has reached a test accuracy of 99%. This means the model is able of detecting ~19.9/20 fraudulent charges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e7e71240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0033778617412545614"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from numpy import mean\n",
    "from numpy import absolute\n",
    "from numpy import sqrt\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "#build multiple linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "#use k-fold CV to evaluate model\n",
    "scores = cross_val_score(model, x, y, scoring='neg_mean_absolute_error',\n",
    "                         cv=cv, n_jobs=-1)\n",
    "\n",
    "#view mean absolute error\n",
    "mean(absolute(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d31d95ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in y_pred: 56962\n",
      "Number of samples in y: 284807\n",
      "First few elements of y_pred: [ 0.00066828  0.00059881 -0.0013353   0.00671809 -0.00142099]\n",
      "First few elements of y: [0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples in y_pred:\", len(y_pred))\n",
    "print(\"Number of samples in y:\", len(y))\n",
    "\n",
    "# Debugging: Check the first few elements of y_pred and y to identify any discrepancies\n",
    "print(\"First few elements of y_pred:\", y_pred[:5])\n",
    "print(\"First few elements of y:\", y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2371d401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c6531396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression Accuracy: 0.5465466115922584\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_ridge = ridge_model.predict(x_test)\n",
    "\n",
    "# Calculate R^2 score\n",
    "ridge_accuracy = r2_score(y_test, y_pred_ridge)\n",
    "\n",
    "print(\"Ridge Regression Accuracy:\", ridge_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b00c2c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lasso Regression\n",
    "lasso_model = Lasso(alpha=1.0)\n",
    "lasso_model.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7c5a8707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression Accuracy: 2.532221819440128e-05\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_lasso = lasso_model.predict(x_test)\n",
    "\n",
    "# Calculate R^2 score\n",
    "lasso_accuracy = r2_score(y_test, y_pred_lasso)\n",
    "\n",
    "print(\"Lasso Regression Accuracy:\", lasso_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f902927c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('polynomialfeatures', PolynomialFeatures()),\n",
       "                ('linearregression', LinearRegression())])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Polynomial Regression\n",
    "degree = 2  # Degree of polynomial features\n",
    "poly_model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "poly_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5b14714d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Regression Accuracy: 0.7094869142372231\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_poly = poly_model.predict(x_test)\n",
    "\n",
    "# Calculate R^2 score\n",
    "poly_accuracy = r2_score(y_test, y_pred_poly)\n",
    "\n",
    "print(\"Polynomial Regression Accuracy:\", poly_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "96adcb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression R^2 score: 0.5465466115922584\n",
      "Lasso Regression R^2 score: 2.532221819440128e-05\n",
      "Polynomial Regression R^2 score: 0.7094869142372231\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Calculate R^2 score for Ridge Regression\n",
    "ridge_r2_score = r2_score(y_test, ridge_model.predict(x_test))\n",
    "print(\"Ridge Regression R^2 score:\", ridge_r2_score)\n",
    "\n",
    "# Calculate R^2 score for Lasso Regression\n",
    "lasso_r2_score = r2_score(y_test, lasso_model.predict(x_test))\n",
    "print(\"Lasso Regression R^2 score:\", lasso_r2_score)\n",
    "\n",
    "# Calculate R^2 score for Polynomial Regression\n",
    "poly_r2_score = r2_score(y_test, poly_model.predict(x_test))\n",
    "print(\"Polynomial Regression R^2 score:\", poly_r2_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "475e4f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "TRAIN MODEL CLASSIFICATION REPORT - Ridge Regression\n",
      "____________________________________________________________________________________________________\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Fraud       1.00      0.49      0.66    227437\n",
      "       Fraud       0.00      1.00      0.01       408\n",
      "\n",
      "    accuracy                           0.49    227845\n",
      "   macro avg       0.50      0.74      0.33    227845\n",
      "weighted avg       1.00      0.49      0.66    227845\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "TEST MODEL CLASSIFICATION REPORT - Ridge Regression\n",
      "____________________________________________________________________________________________________\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Fraud       1.00      1.00      1.00     56878\n",
      "       Fraud       0.83      0.45      0.58        84\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.91      0.73      0.79     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "TRAIN MODEL CLASSIFICATION REPORT - Lasso Regression\n",
      "____________________________________________________________________________________________________\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Fraud       0.00      0.00      0.00    227437\n",
      "       Fraud       0.00      1.00      0.00       408\n",
      "\n",
      "    accuracy                           0.00    227845\n",
      "   macro avg       0.00      0.50      0.00    227845\n",
      "weighted avg       0.00      0.00      0.00    227845\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "TEST MODEL CLASSIFICATION REPORT - Lasso Regression\n",
      "____________________________________________________________________________________________________\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Fraud       1.00      1.00      1.00     56878\n",
      "       Fraud       0.00      0.00      0.00        84\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.50      0.50      0.50     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "____________________________________________________________________________________________________\n",
      "TRAIN MODEL CLASSIFICATION REPORT - Polynomial Regression\n",
      "____________________________________________________________________________________________________\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Fraud       1.00      0.47      0.64    227437\n",
      "       Fraud       0.00      1.00      0.01       408\n",
      "\n",
      "    accuracy                           0.47    227845\n",
      "   macro avg       0.50      0.73      0.32    227845\n",
      "weighted avg       1.00      0.47      0.64    227845\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "TEST MODEL CLASSIFICATION REPORT - Polynomial Regression\n",
      "____________________________________________________________________________________________________\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Fraud       1.00      1.00      1.00     56878\n",
      "       Fraud       0.88      0.77      0.82        84\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.94      0.89      0.91     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def regression_with_report(model, x_train, y_train, x_test):\n",
    "    if model == 'Linear':\n",
    "        regressor = LinearRegression()\n",
    "    elif model == 'Ridge':\n",
    "        regressor = Ridge(alpha=1.0)\n",
    "    elif model == 'Lasso':\n",
    "        regressor = Lasso(alpha=1.0)\n",
    "    elif model == 'Polynomial':\n",
    "        degree = 2  # Degree of polynomial features\n",
    "        regressor = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "\n",
    "    regressor.fit(x_train, y_train)\n",
    "    y_train_pred = regressor.predict(x_train)\n",
    "    y_train_cl_report = classification_report(y_train, y_train_pred > 0, target_names=['No Fraud', 'Fraud'])\n",
    "    print(\"_\" * 100)\n",
    "    print(f\"TRAIN MODEL CLASSIFICATION REPORT - {model} Regression\")\n",
    "    print(\"_\" * 100)\n",
    "    print(y_train_cl_report)\n",
    "    y_test_pred = regressor.predict(x_test)\n",
    "    y_test_pred = [0 if i < 0.5 else 1 for i in y_test_pred]\n",
    "    y_test_cl_report = classification_report(y_test, y_test_pred, target_names=['No Fraud', 'Fraud'])\n",
    "    print(\"_\" * 100)\n",
    "    print(f\"TEST MODEL CLASSIFICATION REPORT - {model} Regression\")\n",
    "    print(\"_\" * 100)\n",
    "    print(y_test_cl_report)\n",
    "    print(\"_\" * 100)\n",
    "    return y_test_pred, regressor\n",
    "\n",
    "# Usage examples:\n",
    "y_test_pred_ridge, ridge_regressor = regression_with_report('Ridge', x_train, y_train, x_test)\n",
    "y_test_pred_lasso, lasso_regressor = regression_with_report('Lasso', x_train, y_train, x_test)\n",
    "y_test_pred_poly, poly_regressor = regression_with_report('Polynomial', x_train, y_train, x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "15f32527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression Metrics:\n",
      "R^2 score: 0.5465466115922584\n",
      "Mean Absolute Error (MAE): 0.003236397278693198\n",
      "Mean Squared Error (MSE): 0.0006677067944095521\n",
      "Root Mean Squared Error (RMSE): 0.025840023111629605\n",
      "\n",
      "Lasso Regression Metrics:\n",
      "R^2 score: 2.532221819440128e-05\n",
      "Mean Absolute Error (MAE): 0.0032573676676732684\n",
      "Mean Squared Error (MSE): 0.00147245539158268\n",
      "Root Mean Squared Error (RMSE): 0.03837258645938113\n",
      "\n",
      "Polynomial Regression Metrics:\n",
      "R^2 score: 0.7094869142372231\n",
      "Mean Absolute Error (MAE): 0.0026440386105417196\n",
      "Mean Squared Error (MSE): 0.00042777839175449725\n",
      "Root Mean Squared Error (RMSE): 0.020682804252675633\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Ridge Regression\n",
    "ridge_y_pred = ridge_model.predict(x_test)\n",
    "\n",
    "ridge_r2_score = r2_score(y_test, ridge_y_pred)\n",
    "ridge_mae = mean_absolute_error(y_test, ridge_y_pred)\n",
    "ridge_mse = mean_squared_error(y_test, ridge_y_pred)\n",
    "ridge_rmse = np.sqrt(ridge_mse)\n",
    "\n",
    "print(\"Ridge Regression Metrics:\")\n",
    "print(\"R^2 score:\", ridge_r2_score)\n",
    "print(\"Mean Absolute Error (MAE):\", ridge_mae)\n",
    "print(\"Mean Squared Error (MSE):\", ridge_mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", ridge_rmse)\n",
    "\n",
    "# Lasso Regression\n",
    "lasso_y_pred = lasso_model.predict(x_test)\n",
    "\n",
    "lasso_r2_score = r2_score(y_test, lasso_y_pred)\n",
    "lasso_mae = mean_absolute_error(y_test, lasso_y_pred)\n",
    "lasso_mse = mean_squared_error(y_test, lasso_y_pred)\n",
    "lasso_rmse = np.sqrt(lasso_mse)\n",
    "\n",
    "print(\"\\nLasso Regression Metrics:\")\n",
    "print(\"R^2 score:\", lasso_r2_score)\n",
    "print(\"Mean Absolute Error (MAE):\", lasso_mae)\n",
    "print(\"Mean Squared Error (MSE):\", lasso_mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", lasso_rmse)\n",
    "\n",
    "# Polynomial Regression\n",
    "poly_y_pred = poly_model.predict(x_test)\n",
    "\n",
    "poly_r2_score = r2_score(y_test, poly_y_pred)\n",
    "poly_mae = mean_absolute_error(y_test, poly_y_pred)\n",
    "poly_mse = mean_squared_error(y_test, poly_y_pred)\n",
    "poly_rmse = np.sqrt(poly_mse)\n",
    "\n",
    "print(\"\\nPolynomial Regression Metrics:\")\n",
    "print(\"R^2 score:\", poly_r2_score)\n",
    "print(\"Mean Absolute Error (MAE):\", poly_mae)\n",
    "print(\"Mean Squared Error (MSE):\", poly_mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", poly_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d31284f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Metrics:\n",
      "R^2 score: 0.5166663660896537\n",
      "Mean Absolute Error (MAE): 0.003439270774698584\n",
      "Mean Squared Error (MSE): 0.0008301184002984185\n",
      "Root Mean Squared Error (RMSE): 0.028811775375676148\n",
      "\n",
      "\n",
      "Ridge Regression Metrics:\n",
      "Accuracy: 0.9988764439450862\n",
      "Precision: 0.8269230769230769\n",
      "Recall: 0.4387755102040816\n",
      "F1-score: 0.5733333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso Regression Metrics:\n",
      "Accuracy: 0.9982795547909132\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=1.56164e-26): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, sym_pos=True,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Polynomial Regression Metrics:\n",
      "Accuracy: 0.999385555282469\n",
      "Precision: 0.8539325842696629\n",
      "Recall: 0.7755102040816326\n",
      "F1-score: 0.8128342245989305\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you have loaded your dataset and split it into features (x) and target variable (y)\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Linear Regression Metrics:\")\n",
    "linear_r2_score = r2_score(y_test, linear_y_pred_continuous)\n",
    "linear_mae = mean_absolute_error(y_test, linear_y_pred_continuous)\n",
    "linear_mse = mean_squared_error(y_test, linear_y_pred_continuous)\n",
    "linear_rmse = np.sqrt(linear_mse)\n",
    "\n",
    "print(\"R^2 score:\", linear_r2_score)\n",
    "print(\"Mean Absolute Error (MAE):\", linear_mae)\n",
    "print(\"Mean Squared Error (MSE):\", linear_mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", linear_rmse)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Ridge Regression\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(x_train, y_train)\n",
    "ridge_y_pred_continuous = ridge_model.predict(x_test)\n",
    "\n",
    "# Convert continuous predictions to binary (using threshold 0.5)\n",
    "ridge_y_pred = (ridge_y_pred_continuous >= 0.5).astype(int)\n",
    "\n",
    "ridge_accuracy = accuracy_score(y_test, ridge_y_pred)\n",
    "ridge_precision = precision_score(y_test, ridge_y_pred)\n",
    "ridge_recall = recall_score(y_test, ridge_y_pred)\n",
    "ridge_f1_score = f1_score(y_test, ridge_y_pred)\n",
    "\n",
    "print(\"Ridge Regression Metrics:\")\n",
    "print(\"Accuracy:\", ridge_accuracy)\n",
    "print(\"Precision:\", ridge_precision)\n",
    "print(\"Recall:\", ridge_recall)\n",
    "print(\"F1-score:\", ridge_f1_score)\n",
    "\n",
    "# Lasso Regression\n",
    "lasso_model = Lasso(alpha=1.0)\n",
    "lasso_model.fit(x_train, y_train)\n",
    "lasso_y_pred_continuous = lasso_model.predict(x_test)\n",
    "\n",
    "# Convert continuous predictions to binary (using threshold 0.5)\n",
    "lasso_y_pred = (lasso_y_pred_continuous >= 0.5).astype(int)\n",
    "\n",
    "lasso_accuracy = accuracy_score(y_test, lasso_y_pred)\n",
    "lasso_precision = precision_score(y_test, lasso_y_pred)\n",
    "lasso_recall = recall_score(y_test, lasso_y_pred)\n",
    "lasso_f1_score = f1_score(y_test, lasso_y_pred)\n",
    "\n",
    "print(\"\\nLasso Regression Metrics:\")\n",
    "print(\"Accuracy:\", lasso_accuracy)\n",
    "print(\"Precision:\", lasso_precision)\n",
    "print(\"Recall:\", lasso_recall)\n",
    "print(\"F1-score:\", lasso_f1_score)\n",
    "\n",
    "# Polynomial Regression\n",
    "degree = 2  # Degree of polynomial features\n",
    "poly_model = make_pipeline(PolynomialFeatures(degree), Ridge())  # Using Ridge as part of the pipeline for stability\n",
    "poly_model.fit(x_train, y_train)\n",
    "poly_y_pred_continuous = poly_model.predict(x_test)\n",
    "\n",
    "# Convert continuous predictions to binary (using threshold 0.5)\n",
    "poly_y_pred = (poly_y_pred_continuous >= 0.5).astype(int)\n",
    "\n",
    "poly_accuracy = accuracy_score(y_test, poly_y_pred)\n",
    "poly_precision = precision_score(y_test, poly_y_pred)\n",
    "poly_recall = recall_score(y_test, poly_y_pred)\n",
    "poly_f1_score = f1_score(y_test, poly_y_pred)\n",
    "\n",
    "print(\"\\nPolynomial Regression Metrics:\")\n",
    "print(\"Accuracy:\", poly_accuracy)\n",
    "print(\"Precision:\", poly_precision)\n",
    "print(\"Recall:\", poly_recall)\n",
    "print(\"F1-score:\", poly_f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "68e5bde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Metrics:\n",
      "Accuracy: 0.9988764439450862\n",
      "Precision: 0.8269230769230769\n",
      "Recall: 0.4387755102040816\n",
      "F1-score: 0.5733333333333333\n",
      "R^2 score: 0.5166663660896537\n",
      "Mean Absolute Error (MAE): 0.003439270774698584\n",
      "Mean Squared Error (MSE): 0.0008301184002984185\n",
      "Root Mean Squared Error (RMSE): 0.028811775375676148\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Linear Regression\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(x_train, y_train)\n",
    "linear_y_pred_continuous = linear_model.predict(x_test)\n",
    "\n",
    "# Convert continuous predictions to binary (using threshold 0.5)\n",
    "linear_y_pred = (linear_y_pred_continuous >= 0.5).astype(int)\n",
    "\n",
    "linear_accuracy = accuracy_score(y_test, linear_y_pred)\n",
    "linear_precision = precision_score(y_test, linear_y_pred)\n",
    "linear_recall = recall_score(y_test, linear_y_pred)\n",
    "linear_f1_score = f1_score(y_test, linear_y_pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc71a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
